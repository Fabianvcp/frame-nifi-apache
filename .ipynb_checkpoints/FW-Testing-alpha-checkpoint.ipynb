{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc35c8d9-4690-4b92-8da9-7c4b67dee261",
   "metadata": {},
   "source": [
    "# Api Nifi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93738b16-cbcc-48d4-9578-97c4653e8182",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5066fc80-440c-45f9-8583-d78532995a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib import response\n",
    "import requests\n",
    "import json\n",
    "import urllib3\n",
    "from IPython.display import display\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "##desactivamos los mensajes de peligro\n",
    "from prettytable import PrettyTable\n",
    "from prettytable.colortable import RESET_CODE, ColorTable, Theme\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66520153-a135-48ce-847d-7bd2167b81aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variables Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2bb77c69-05f7-4c1f-9054-bd8a91e92e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"EXD21089\"\n",
    "PASSWORD = \"Batocera7284\"\n",
    "URL = \"https://cdf01it-01adl.claro.amx:8443/nifi-api\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03872b-c3a2-4fd9-a0d5-cba88f87d7e0",
   "metadata": {},
   "source": [
    "## Recorrido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8c42b-9bf3-4abf-aacd-d45562c33461",
   "metadata": {},
   "source": [
    "### Acceso al token de la api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d8c7fb5-633f-4b00-9942-a56448c9a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtención del token de nifi\n",
    "def obtenerToken(URL):\n",
    "    ingreso = \"/access/token?username={}&password={}\".format(USERNAME, PASSWORD)\n",
    "    HeadersSinJson = {'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8', 'User-Agent': 'PostmanRuntime/7.29.0'}\n",
    "    response = requests.post(URL+ingreso, headers=HeadersSinJson, verify = False)        \n",
    "    if response.status_code == 201 or response.status_code == 200:\n",
    "       #devuelve el token en byte, no como string\n",
    "        base = response.content\n",
    "        token = base.decode(\"utf-8\")\n",
    "        return token\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "    \n",
    "    #Recorremos el archivo con el escenario de prueba\n",
    "\n",
    "TokenNifi = obtenerToken(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9b76b-7f4b-43a1-bbd8-f8000ef1a713",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Diccionarios y tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5faf5-4eea-432d-bd7c-09d7168403e3",
   "metadata": {},
   "source": [
    "### Diccionarios y lector de los procesadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36f227d8-7e00-4fce-bf52-bfc4c689b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    @uthor: Leonardo Alverto Rébola\n",
    "    Description: Creacion de una clase de diccionario\n",
    "\"\"\"\n",
    "class CustomDict(dict):\n",
    "    #__init___function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "        \n",
    "    #Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "        \n",
    "class TableDict(dict):\n",
    "    #__init___function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "        \n",
    "    #Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value\n",
    "        \n",
    "class GroupsDict(dict):\n",
    "    #__init___function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "        \n",
    "    #Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value\n",
    "        \n",
    "#instancia del dict\n",
    "dict_proccessors = CustomDict()\n",
    "    \n",
    "#desglozamos y buscamos los datos de los proccessors\n",
    "def loadProccessors(pg):\n",
    "    if type(pg) == int:\n",
    "        return False\n",
    "    else:\n",
    "        proccessors = pg['processGroupFlow']['flow']['processors']\n",
    "        for proccessor in proccessors:\n",
    "            ##error add() takes 3 positional arguments but 4 were given puede ser por que dentro revision tiene dos valores\n",
    "            dict_proccessors.add(proccessor['component']['name'], proccessor['component']['id'])\n",
    "        return dict_proccessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232f538-fd23-4c2f-9b3a-2d560e7c1cda",
   "metadata": {},
   "source": [
    "### Diccionario y lector de conectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55a38a2a-63f2-4ef8-bf48-c07c775de6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Connection:\n",
    "    def __init__(self,id, name, sourceId, sourceName, destinationId, destinationName):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.sourceId = sourceId\n",
    "        self.sourceName = sourceName\n",
    "        self.destinationId = destinationId\n",
    "        self.destinationName = destinationName\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"id:{},name:{}, sourceId:{}, sourceName:{}, destinationId:{}, destinationName:{}\".format(self.id, self.name, self.sourceId ,self.sourceName , self.destinationId, self.destinationName)\n",
    "\n",
    "dict_connections = CustomDict()\n",
    "def loadConnections(pg):\n",
    "    if type(pg) == int:\n",
    "        return False\n",
    "    else:\n",
    "        connections = pg['processGroupFlow']['flow']['connections']\n",
    "        for conection in connections:\n",
    "            dict_connections.add(conection['component']['name'],\n",
    "                                 Connection(\n",
    "                                    conection['component']['id'],\n",
    "                                    conection['component']['name'],\n",
    "                                    conection['component']['source']['id'],\n",
    "                                    conection['component']['source']['name'],\n",
    "                                    conection['component']['destination']['id'],\n",
    "                                    conection['component']['destination']['name']\n",
    "                                 )\n",
    "                                )\n",
    "        return dict_connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2fcad-aba0-455e-89d3-e8207a0e5f0e",
   "metadata": {},
   "source": [
    "### Diccionario para tabla de procesadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9c887e59-4e44-4d24-9422-9f77dc7d578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableProcessor:\n",
    "    def __init__(self,name, tipo , status, flowFilesIn, flowFilesOut, taskCount):\n",
    "        self.name = name\n",
    "        self.tipo = tipo\n",
    "        self.status = status\n",
    "        self.flowFilesIn = flowFilesIn\n",
    "        self.flowFilesOut = flowFilesOut\n",
    "        self.taskCount = taskCount\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"name:{},tipo:{}, status:{}, flowFilesIn:{}, flowFilesOut:{}, taskCount:{}\".format(self.name, self.tipo, self.status ,self.flowFilesIn , self.flowFilesOut, self.taskCount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266be06-946e-4d3f-8cc6-d12c2dba684a",
   "metadata": {},
   "source": [
    "### diccionario para tabla de Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8b853df-5ed0-41d4-843c-27d90e577623",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableConnection:\n",
    "    def __init__(self, name, sourceName, destinationName, flowFilesQueued, queued, queuedCount, flowFilesIn, aceptados, flowFilesOut, procesados):\n",
    "        ## aceptado = input\n",
    "        ## procesadors = output\n",
    "        self.name = name\n",
    "        self.sourceName = sourceName\n",
    "        self.destinationName = destinationName\n",
    "        self.flowFilesQueued = flowFilesQueued\n",
    "        self.queued = queued\n",
    "        self.queuedCount = queuedCount\n",
    "        self.flowFilesIn = flowFilesIn\n",
    "        self.aceptado = aceptados\n",
    "        self.flowFilesOut = flowFilesOut\n",
    "        self.procesados =procesados\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"name:{}, sourceName:{}, destinationName:{}, flowFilesQueued:{}, queued:{}, queuedCount:{}, flowFilesIn:{}, aceptados:{}, flowFilesOut:{}, procesados:{}\".format(self.name, self.sourceName, self.destinationName, self.flowFilesQueued, self.queued, self.queuedCount, self.flowFilesIn, self.aceptados, self.flowFilesOut, self.procesados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d00d5-3e3a-412c-b673-d0044e6192df",
   "metadata": {},
   "source": [
    "### Diccionario  y lector de ProcessGroup anidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "139a896d-5fd7-4d6f-af7d-1f8011ff5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class processGroupDict(dict):\n",
    "    #__init___function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "        \n",
    "    #Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "class processGroup:\n",
    "    def __init__(self, name, uuid):\n",
    "        self.name = name,\n",
    "        self.uuid = uuid\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"name:{} ,uuid:{}\".format(self.name, self.uuid)\n",
    "    \n",
    "dict_proccessgroup = processGroupDict()\n",
    "\n",
    "def loadProcessgroups(pg):\n",
    "    if type(pg) == int:\n",
    "        return False\n",
    "    else:\n",
    "        proccessgroups = pg['processGroupFlow']['flow']['processGroups']\n",
    "        for proccessgroup in proccessgroups:\n",
    "            ##error add() takes 3 positional arguments but 4 were given puede ser por que dentro revision tiene dos valores\n",
    "            dict_proccessgroup.add(proccessgroup['component']['name'], proccessgroup['component']['id'])                    \n",
    "        return dict_proccessgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975d962-e6fe-4c0c-9d03-9dbe74814d43",
   "metadata": {},
   "source": [
    "## Funciones proccessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16330183-1b75-43bf-a9c0-0c2f2376a8e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GET Processors groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac8363e3-7e61-4f55-8105-9f57928219e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtencion de datos del proccess groups\n",
    "dict_tablep = TableDict()\n",
    "def getProccessGroups(TokenNifi, id):\n",
    "    flowProccessGroupsURI = URL + \"/flow/process-groups/\"\n",
    "    #URL al process-group\n",
    "    url =flowProccessGroupsURI+id\n",
    "    \n",
    "    #encabezado\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':'Bearer ' + TokenNifi}\n",
    "    \n",
    "    #almacena el request\n",
    "    payload ={'uiOnly':True}\n",
    "    response = requests.get(url, headers=headers, verify=False, params=payload)\n",
    "    \n",
    "    if response.status_code == 201 or response.status_code == 200: \n",
    "        response_json = response.json()\n",
    "        return response_json\n",
    "    else:\n",
    "        return response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a28284-802f-4a9f-8fa1-9d9d6c2ca464",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GET Proccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87493df2-4597-47a6-a36b-0bf4e57359be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer los datos del proccesor\n",
    "def GetProccessor(id):\n",
    "    #agregar al url\n",
    "    EnviarToken = \"/processors/\"+id\n",
    "    #encabezado\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':'Bearer ' + TokenNifi}\n",
    "    #almacena el requestzzz\n",
    "    response = requests.get(URL+EnviarToken,headers=headers,verify=False)\n",
    "    #Prueba\n",
    "    if response.status_code == 201 or response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return response_json['revision']\n",
    "    else:\n",
    "        display(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d158b9a-a85b-48b1-81e5-80c60dbb6c12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PLAY Proccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78cc7129-78f8-4ba0-a411-89a3ee36946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tableP = CustomDict()\n",
    "def PlayProccessor(uuid,revision):\n",
    "    #agregar al url\n",
    "    EnviarToken = \"/processors/\"+uuid+\"/run-status\"\n",
    "    #encabezado\n",
    "    headers = {'Accept': '*/*','Content-Type':'application/json;charset=UTF-8','User-Agent': 'PostmanRuntime/7.29.0', 'Authorization':'Bearer '+TokenNifi}\n",
    "    #almacena el request\n",
    "    data={'revision': revision,\"state\": \"RUNNING\"}\n",
    "    response = requests.put(URL+EnviarToken,headers=headers,verify=False, json=data)\n",
    "    #Prueba\n",
    "    if response.status_code == 201 or response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        procesador = response_json[\"status\"]\n",
    "        \n",
    "        dict_tableP.add(procesador[\"aggregateSnapshot\"]['name']+\"-Play\",\n",
    "                        TableProcessor(\n",
    "                            procesador[\"aggregateSnapshot\"]['name'],\n",
    "                            procesador[\"aggregateSnapshot\"]['type'],\n",
    "                            procesador[\"aggregateSnapshot\"]['runStatus'],\n",
    "                            procesador[\"aggregateSnapshot\"]['flowFilesIn'],\n",
    "                            procesador[\"aggregateSnapshot\"]['flowFilesOut'],\n",
    "                            procesador[\"aggregateSnapshot\"]['taskCount']\n",
    "                        )\n",
    "                    )\n",
    " \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4512d5e-1fa5-4810-a9d8-bfb181b1f7a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STOP Proccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58c53677-3d95-4402-888c-1a6d0b3773b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StopProccessor(uuid,stoped):\n",
    "    #agregar al url\n",
    "    EnviarToken = \"/processors/\"+uuid+\"/run-status\"\n",
    "    #encabezado\n",
    "    headers = {'Accept': '*/*','Content-Type':'application/json;charset=UTF-8','User-Agent': 'PostmanRuntime/7.29.0', 'Authorization':'Bearer '+TokenNifi}\n",
    "    #almacena el request\n",
    "    data={\"revision\": stoped,\"state\": \"STOPPED\"}\n",
    "    response = requests.put(URL+EnviarToken,headers=headers,verify=False, json=data)\n",
    "    #Prueba\n",
    "    if response.status_code == 201 or response.status_code == 200: \n",
    "        response_json = response.json()\n",
    "        procesador = response_json[\"status\"]\n",
    "        \n",
    "        dict_tableP.add(procesador[\"aggregateSnapshot\"]['name']+\"-Stop\",\n",
    "                        TableProcessor(\n",
    "                            procesador[\"aggregateSnapshot\"]['name'],\n",
    "                            procesador[\"aggregateSnapshot\"]['type'],\n",
    "                            procesador[\"aggregateSnapshot\"]['runStatus'],\n",
    "                            procesador[\"aggregateSnapshot\"]['flowFilesIn'],\n",
    "                            procesador[\"aggregateSnapshot\"]['flowFilesOut'],\n",
    "                            procesador[\"aggregateSnapshot\"]['taskCount']\n",
    "                        )\n",
    "                    )\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd4f89-25d3-4d8e-addf-958c29428514",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CLEAR STATE Proccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "155f8145-9f89-47e7-b8eb-88e2a7fa0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClearProccessor(id):\n",
    "    #aregar al url\n",
    "    EnviarToken = \"/processors/\"+id+\"/state/clear-requests\"\n",
    "    #encabezado\n",
    "    headers = {'Accept': '*/*','Content-Type':'application/json;charset=UTF-8','User-Agent': 'PostmanRuntime/7.29.0', 'Authorization':'Bearer '+TokenNifi}\n",
    "    #almacena el request\n",
    "    response = requests.post(URL+EnviarToken,headers=headers,verify=False)\n",
    "    #Pueba\n",
    "    if response.status_code == 201 or response.status_code == 200:            \n",
    "        print(\"Datos del State limpiados\")\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4aed1-d45f-41bb-88c9-7a64706133cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connecctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7150d5-1a83-46c3-ac4c-5233e0fd58cf",
   "metadata": {},
   "source": [
    "### Get connecction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a842da1-6dab-430f-bdd6-009f7e836bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tableC = TableDict()\n",
    "def GetConnecction(id):\n",
    "    #agregar al url\n",
    "    EnviarToken = \"/connections/\"+id\n",
    "    #encabezado\n",
    "    headers = {'Accept': '*/*','Content-Type':'application/json;charset=UTF-8','User-Agent': 'PostmanRuntime/7.29.0', 'Authorization':'Bearer '+TokenNifi}\n",
    "    #almacena el request\n",
    "    response = requests.get(URL+EnviarToken,headers=headers,verify=False)\n",
    "    #Prueba\n",
    "    if response.status_code == 201 or response.status_code == 200: \n",
    "        response_json = response.json()\n",
    "        connections = response_json[\"status\"]\n",
    "        version = response_json[\"component\"]['source'][\"running\"]\n",
    "        dict_tableC.add(connections[\"aggregateSnapshot\"]['name']+str(version),\n",
    "                        TableConnection(\n",
    "                            connections[\"aggregateSnapshot\"]['name'],\n",
    "                            connections[\"aggregateSnapshot\"]['sourceName'],\n",
    "                            connections[\"aggregateSnapshot\"]['destinationName'],\n",
    "                            connections[\"aggregateSnapshot\"]['flowFilesQueued'],\n",
    "                            connections[\"aggregateSnapshot\"]['queued'],\n",
    "                            connections[\"aggregateSnapshot\"]['queuedCount'],\n",
    "                            connections[\"aggregateSnapshot\"]['flowFilesIn'],\n",
    "                            connections[\"aggregateSnapshot\"]['input'],\n",
    "                            connections[\"aggregateSnapshot\"]['flowFilesOut'],\n",
    "                            connections[\"aggregateSnapshot\"]['output']\n",
    "                        )\n",
    "                    )\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d3b51-11bc-4faa-a3a1-33dae4e6ceba",
   "metadata": {},
   "source": [
    "## Generadores de tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf75e6f-fd39-439d-a6d2-b266410e9291",
   "metadata": {},
   "source": [
    "### Tabla de procesadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca083755-aedc-417d-addb-54d7b55479db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informeTablaProcessor():\n",
    "    diccionarios = dict(dict_tableP)\n",
    "    x = PrettyTable([\"Nombre\", \"Tipo\", \"Estatus\", \"flowFiles aceptados\", \"flowFiles transferido\", \"Tareas Ejecutadas\"])\n",
    "\n",
    "    for diccionario in diccionarios.keys():\n",
    "        connection = dict_tableP.get(diccionario, \"Processor no encontrado\")\n",
    "        conecetor = connection.__dict__\n",
    "        x.add_row([conecetor[\"name\"],conecetor[\"tipo\"], conecetor[\"status\"], conecetor[\"flowFilesIn\"],conecetor[\"flowFilesOut\"],conecetor[\"taskCount\"]])\n",
    "    print(x.get_string(title=\"Procesadores\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ade2a2-bcca-4230-b7f5-cd7a06e51720",
   "metadata": {},
   "source": [
    "### Tabla de conectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "823a3411-7cea-4e52-a533-d9243852ad68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informeTablaconnector():\n",
    "    diccionaries = dict(dict_tableC)\n",
    "    y = PrettyTable([\"Nombre\", \"Origen\", \"Destino\",\"flowFiles en espera\",\"En espera\", \"Cantidad en espera\", \"flowFiles aceptados\", \"Tamaño archivos aceptados\",\"flowFiles transferido\", \"Tamaño archivos procesados\"])\n",
    "    for diccies in diccionaries.keys():\n",
    "        connection = dict_tableC.get(diccies, \"Processor no encontrado\")\n",
    "        conecetor = connection.__dict__\n",
    "        y.add_row([conecetor[\"name\"],conecetor[\"sourceName\"],conecetor[\"destinationName\"],conecetor[\"flowFilesQueued\"],conecetor[\"queued\"],conecetor[\"queuedCount\"],conecetor[\"flowFilesIn\"],conecetor[\"aceptado\"],conecetor[\"flowFilesOut\"],conecetor[\"procesados\"]])\n",
    "    print(y.get_string(title=\"Conectores\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fba8ee-df92-45b1-aeab-f17b469436ae",
   "metadata": {},
   "source": [
    "## Lectura del caso de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e877f254-94f0-4beb-a9fe-b0e4c05430ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FEATURE Pruebas de USSD-SMS'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SCENARIO Se espera ejecuciÃ³n exitosa por 29'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a9cdf847-59e7-17e8-0000-00000563997c\n",
      ">>>>> ProcessGroup >>>>> USSD-SMS  07203bdb-7bf9-1f52-8b20-7a803e03ba66\n"
     ]
    }
   ],
   "source": [
    "def getIDfromLine(line):\n",
    "    return line.split(\"'\")[1]\n",
    "\n",
    "def readFileInput():\n",
    "    inputfile = open(\"ussd-sms.txt\",'r')\n",
    "    lines = inputfile.readlines()\n",
    "    for line in lines:\n",
    "        readEscenario(line)\n",
    "        \n",
    "def readEscenario(line):\n",
    "    if \"FEATURE\" in line.upper():\n",
    "        display(\"FEATURE \"+getIDfromLine(line))\n",
    "    elif \"SCENARIO\" in line.upper():\n",
    "        display(\"SCENARIO \"+getIDfromLine(line))\n",
    "    elif \"DATAFLOW\" in line.upper():\n",
    "               #UUID del proccessgroups ingresado en el archivo de txt\n",
    "        uuid = getIDfromLine(line)\n",
    "        print(uuid)\n",
    "               ##obtenemos los datos del proccessgroup\n",
    "        if getProccessGroups(TokenNifi, uuid) == False:            \n",
    "            warnings.filterwarnings(\"ignore\") \n",
    "            sys.exit('exiting...')\n",
    "        else:\n",
    "            loadProccessors(getProccessGroups(TokenNifi, uuid))\n",
    "            loadConnections(getProccessGroups(TokenNifi, uuid))\n",
    "            loadProcessgroups(getProccessGroups(TokenNifi, uuid))\n",
    "        ### en get proccessGroups si sale 400 cerrar el ciclo con exit \n",
    "######################################################################################################################################################################################################        \n",
    "    elif \"PLAY\" in line.upper():\n",
    "        name = getIDfromLine(line)\n",
    "        uuid = dict_proccessors.get(name, \"Processor no encontrado\")\n",
    "        revision = GetProccessor(uuid)\n",
    "        status_code = PlayProccessor(uuid,revision)\n",
    "        if status_code == True:\n",
    "            print(\"\\n\")\n",
    "            print(\">>>>> PLAY >>>>> \" + name + \" con UUID \" + uuid)\n",
    "            del revision\n",
    "            del uuid\n",
    "            del name\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            try:\n",
    "                warnings.filterwarnings(\"ignore\")            \n",
    "                sys.exit('exiting...')            \n",
    "            except TypeError:\n",
    "                print(\"Los datos son incompatibles\")\n",
    " ######################################################################################################################################################################################################         \n",
    "    elif \"STOP\" in line.upper():\n",
    "        name = getIDfromLine(line)\n",
    "        uuid = dict_proccessors.get(name, \"Processor no encontrado\")        \n",
    "        stoped = GetProccessor(uuid)\n",
    "        status_code = StopProccessor(uuid,stoped)\n",
    "        if status_code == True:\n",
    "            print(\"\\n\")\n",
    "            print(\">>>>> STOP >>>>> \" + name + \" con UUID \" + uuid)\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            try:\n",
    "                warnings.filterwarnings(\"ignore\")            \n",
    "                sys.exit('exiting...')            \n",
    "            except TypeError:\n",
    "                print(\"Los datos son incompatibles\")\n",
    "########################################################################################################################################################################################################        \n",
    "    elif \"PROCESSGROUP\" in line.upper():        \n",
    "        name = getIDfromLine(line)\n",
    "        uuid = dict_proccessgroup.get(name, \"ProcessGroup no encontrado\")\n",
    "        loadProccessors(getProccessGroups(TokenNifi, uuid))\n",
    "        loadConnections(getProccessGroups(TokenNifi, uuid))\n",
    "        print(\">>>>> ProcessGroup >>>>> \" + name +\"  \"+ uuid)\n",
    "        \n",
    "        \n",
    "########################################################################################################################################################################################################        \n",
    "    elif \"CHECK\" in line.upper(): \n",
    "        \n",
    "        name = getIDfromLine(line)        \n",
    "        connection = dict_connections.get(name, \"Conector no encontrado\")\n",
    "        if not type(connection) == str:\n",
    "            conecetor = connection.__dict__\n",
    "            flowfile = GetConnecction(conecetor['id'])\n",
    "            if flowfile == True:\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                try:\n",
    "                    warnings.filterwarnings(\"ignore\")            \n",
    "                    sys.exit('exiting...')            \n",
    "                except TypeError:\n",
    "                    print(\"Los datos son incompatibles\")\n",
    "        else:\n",
    "            try:\n",
    "                warnings.filterwarnings(\"ignore\")            \n",
    "                sys.exit('exiting...')            \n",
    "            except TypeError:\n",
    "                print(\"Los datos son incompatibles\")\n",
    "            \n",
    "########################################################################################################################################################################################################        \n",
    "    elif \"CLEAR\" in line.upper():\n",
    "        name = getIDfromLine(line)\n",
    "        uuid = dict_proccessors.get(name, \"Processor no encontrado\")        \n",
    "        stoped = GetProccessor(uuid)\n",
    "        status_code = ClearProccessor(uuid)\n",
    "        if status_code == True:\n",
    "            print(\"\\n\")\n",
    "            print(\">>>>> Clear >>>>> \" + name + \" con UUID \" + uuid)\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            try:\n",
    "                warnings.filterwarnings(\"ignore\")            \n",
    "                sys.exit('exiting...')            \n",
    "            except TypeError:\n",
    "                print(\"Los datos son incompatibles\")\n",
    "########################################################################################################################################################################################################\n",
    "    elif \"IMPRIMIR\" in line.upper():\n",
    "        \n",
    "        Impresion = getIDfromLine(line)\n",
    "        informeTablaProcessor()\n",
    "        informeTablaconnector()\n",
    "        \n",
    "    \n",
    "readFileInput()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68f498-f5cb-42ab-8b46-8b14334c22ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
